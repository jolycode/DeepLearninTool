{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRIT5uC6AYsR"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install -U pytorch-lightning --no-cache-dir"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import pickle\n",
        "torch.cuda.empty_cache()\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from sklearn.model_selection import train_test_split\n",
        "from termcolor import colored\n",
        "import textwrap\n",
        "\n",
        "from transformers import (\n",
        "    AdamW,\n",
        "    T5ForConditionalGeneration,\n",
        "    T5TokenizerFast as T5Tokenizer\n",
        ")\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "yRNAxFi1cwq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "rcParams['figure.figsize'] = 16, 10"
      ],
      "metadata": {
        "id": "cQLrWbU4cwt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pl.seed_everything(42)"
      ],
      "metadata": {
        "id": "C5TVWPshcwws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1pGYqAhMEO2B8GABtqxhAxEzNftkY5bWd"
      ],
      "metadata": {
        "id": "Fo3_Tbsccwzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1du4LNlXMpAIz3XTRqbMgnVl2nr8RjDFu"
      ],
      "metadata": {
        "id": "EFHsfUn_cw2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q archive2.zip -d data"
      ],
      "metadata": {
        "id": "OVnvu3elcw5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"data/summary.csv\", encoding=\"latin-1\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "crqYC-9Dcw8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/my-dataset-train.csv\", encoding=\"latin-1\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "dpByxdmQcw--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[[\"text\", \"summ\"]]\n",
        "df = df.dropna()\n",
        "df.head()"
      ],
      "metadata": {
        "id": "WHcyUK5McxBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = [\"summary\", \"text\"]\n",
        "df = df.dropna()\n",
        "df.head()"
      ],
      "metadata": {
        "id": "EdRExMqjcxEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape\n",
        "train_df, test_df = train_test_split(df, test_size=0.1)\n",
        "train_df.shape, test_df.shape"
      ],
      "metadata": {
        "id": "ZFgtBsaAcxHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SummaryDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        data: pd.DataFrame,\n",
        "        tokenizer: T5Tokenizer,\n",
        "        text_max_token_len: int = 512,\n",
        "        summary_max_token_len: int = 128\n",
        "    ):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = data\n",
        "        self.text_max_token_len = text_max_token_len\n",
        "        self.summary_max_token_len = summary_max_token_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        data_row = self.data.iloc[index]\n",
        "\n",
        "        text = data_row['text']\n",
        "\n",
        "        text_encoding = tokenizer(\n",
        "            text,\n",
        "            max_length=self.text_max_token_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            add_special_tokens=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        summary_encoding = tokenizer(\n",
        "            data_row['summary'],\n",
        "            max_length=self.summary_max_token_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            add_special_tokens=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        labels = summary_encoding['input_ids']\n",
        "        labels[labels == 0] = -100 # to make sure we have correct labels for T5 text generation\n",
        "\n",
        "        return dict(\n",
        "            text=text,\n",
        "            summary=data_row['summary'],\n",
        "            text_input_ids=text_encoding['input_ids'].flatten(),\n",
        "            text_attention_mask=text_encoding['attention_mask'].flatten(),\n",
        "            labels=labels.flatten(),\n",
        "            labels_attention_mask=summary_encoding['attention_mask'].flatten()\n",
        "        )"
      ],
      "metadata": {
        "id": "76zljmUkcxJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SummaryDataModule(pl.LightningDataModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        train_df: pd.DataFrame,\n",
        "        test_df: pd.DataFrame,\n",
        "        tokenizer: T5Tokenizer,\n",
        "        batch_size: int = 8,\n",
        "        text_max_token_len: int = 512,\n",
        "        summary_max_token_len: int = 128\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.train_df = train_df\n",
        "        self.test_df = test_df\n",
        "        self.batch_size = batch_size\n",
        "        self.tokenizer = tokenizer\n",
        "        self.text_max_token_len = text_max_token_len\n",
        "        self.summary_max_token_len = summary_max_token_len\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        self.train_dataset = SummaryDataset(\n",
        "            self.train_df,\n",
        "            self.tokenizer,\n",
        "            self.text_max_token_len,\n",
        "            self.summary_max_token_len\n",
        "        )\n",
        "        self.test_dataset = SummaryDataset(\n",
        "            self.test_df,\n",
        "            self.tokenizer,\n",
        "            self.text_max_token_len,\n",
        "            self.summary_max_token_len\n",
        "        )\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.train_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=2\n",
        "        )\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.test_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=2\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.test_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=2\n",
        "        )"
      ],
      "metadata": {
        "id": "s2cJ6L2tcxL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = 't5-base'\n",
        "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)"
      ],
      "metadata": {
        "id": "f82I_ILwdFlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 3\n",
        "BATCH_SIZE = 8\n",
        "data_module = SummaryDataModule(train_df, test_df, tokenizer)"
      ],
      "metadata": {
        "id": "horRFfBKdFoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SummaryModel(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME, return_dict=True)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, decoder_attention_mask, labels=None):\n",
        "        output = self.model(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels,\n",
        "            decoder_attention_mask=decoder_attention_mask\n",
        "        )\n",
        "\n",
        "        return output.loss, output.logits\n",
        "    def generate(\n",
        "            self,\n",
        "            input_ids,\n",
        "            attention_mask,\n",
        "            max_length,\n",
        "            num_beams=2,\n",
        "            repetition_penalty=2.5,\n",
        "            length_penalty=1.0,\n",
        "            early_stopping=True,\n",
        "            decoder_start_token_id=None\n",
        "        ):\n",
        "            generated_ids = self.model.generate(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                max_length=max_length,\n",
        "                num_beams=num_beams,\n",
        "                repetition_penalty=repetition_penalty,\n",
        "                length_penalty=length_penalty,\n",
        "                early_stopping=early_stopping,\n",
        "                decoder_start_token_id=decoder_start_token_id\n",
        "            )\n",
        "\n",
        "            preds = []\n",
        "            for gen_id in generated_ids:\n",
        "                preds.append(tokenizer.decode(gen_id, skip_special_tokens=True, clean_up_tokenization_spaces=True))\n",
        "\n",
        "            return \"\".join(preds)\n",
        "    def training_step(self, batch, batch_size):\n",
        "        input_ids = batch['text_input_ids']\n",
        "        attention_mask = batch['text_attention_mask']\n",
        "        labels = batch['labels']\n",
        "        labels_attention_mask = batch['labels_attention_mask']\n",
        "\n",
        "        loss, outputs = self(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            decoder_attention_mask=labels_attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_size):\n",
        "        input_ids = batch['text_input_ids']\n",
        "        attention_mask = batch['text_attention_mask']\n",
        "        labels = batch['labels']\n",
        "        labels_attention_mask = batch['labels_attention_mask']\n",
        "\n",
        "        loss, outputs = self(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            decoder_attention_mask=labels_attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_size):\n",
        "        input_ids = batch['text_input_ids']\n",
        "        attention_mask = batch['text_attention_mask']\n",
        "        labels = batch['labels']\n",
        "        labels_attention_mask = batch['labels_attention_mask']\n",
        "\n",
        "        loss, outputs = self(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            decoder_attention_mask=labels_attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return AdamW(self.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "PUI1PpsldFq2",
        "outputId": "dcd7eaa0-1a69-45a4-f44f-4b178104386e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8a05d22c1d83>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mSummaryModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLightningModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5ForConditionalGeneration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pl' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = SummaryModel()"
      ],
      "metadata": {
        "id": "ek-5IvendFth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./lightning_logs"
      ],
      "metadata": {
        "id": "saHBV_9JdFv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_callback = ModelCheckpoint(\n",
        "    dirpath='checkpoints',\n",
        "    filename='best-checkpoint',\n",
        "    save_top_k=1,\n",
        "    verbose=True,\n",
        "    monitor='val_loss',\n",
        "    mode='min'\n",
        ")\n",
        "\n",
        "logger = TensorBoardLogger(\"lightning_logs\", name='summary')\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    logger=logger,\n",
        "    callbacks=checkpoint_callback,\n",
        "    accelerator=\"gpu\",\n",
        "    max_epochs=N_EPOCHS\n",
        "    #gpus=1,\n",
        "    #progress_bar_refresh_rate=30\n",
        ")"
      ],
      "metadata": {
        "id": "tduzRLG8cxOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(model, data_module)"
      ],
      "metadata": {
        "id": "J2A4TLmNdNdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = SummaryModel.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
        "trained_model.freeze()"
      ],
      "metadata": {
        "id": "PQ5O_Ix8dNf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to('cpu')"
      ],
      "metadata": {
        "id": "L9xjEwzjdNiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = open('summarization_model.pkl', 'wb')\n",
        "pickle.dump(trained_model.model, filename)"
      ],
      "metadata": {
        "id": "Fiy5tqsLdNkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = pickle.load(open('summarization_model.pkl', 'rb'))"
      ],
      "metadata": {
        "id": "xQ7l0dihdNnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarizeText(text):\n",
        "    text_encoding = tokenizer(\n",
        "        text,\n",
        "        max_length=512,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        add_special_tokens=True,\n",
        "        return_tensors='pt'\n",
        "    ).to(model2.device)\n",
        "\n",
        "    generated_ids = model2.generate(\n",
        "        input_ids=text_encoding['input_ids'],\n",
        "        attention_mask=text_encoding['attention_mask'],\n",
        "        max_length=150,\n",
        "        num_beams=2,\n",
        "        repetition_penalty=2.5,\n",
        "        length_penalty=1.0,\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "    preds = [\n",
        "            tokenizer.decode(gen_id, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "            for gen_id in generated_ids\n",
        "    ]\n",
        "    return \"\".join(preds)"
      ],
      "metadata": {
        "id": "FxYWQcsndY8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textstr = \"A 38-year-old woman in the US, who was apprehended twice for allegedly trying to jump the White House fence last week, has been arrested for scaling a fence at the Treasury Building next to the White House. She was charged with unlawful entry and contempt of court.\"\n",
        "model_summary = summarizeText(textstr)\n",
        "print('\\nSummary:', '\\n'+ model_summary)"
      ],
      "metadata": {
        "id": "8tJXImgudY_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QgtLJKDfdZBj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}